#!/usr/bin/env python3
"""
æ­¥éª¤4: æ‰¹é‡å¯¼å…¥æ•°æ®åº“ï¼Œå°†å¤„ç†å¥½çš„æ•°æ®å¯¼å…¥SPXåç«¯æ•°æ®åº“
"""

import json
import os
import sys
from pathlib import Path
from typing import List, Dict, Any
import mysql.connector
from mysql.connector import Error
import time
from tqdm import tqdm

class DatabaseImporter:
    def __init__(self, config_path: str = "config.json"):
        with open(config_path, 'r', encoding='utf-8') as f:
            self.config = json.load(f)
        
        self.db_config = self.config['database']
        self.batch_size = self.config['output']['batch_size']
        self.output_dir = Path("output")
        
        self.connection = None

    def connect_to_database(self) -> bool:
        """è¿æ¥åˆ°æ•°æ®åº“"""
        try:
            print("ğŸ”Œ Connecting to database...")
            
            self.connection = mysql.connector.connect(
                host=self.db_config['host'],
                port=self.db_config['port'],
                user=self.db_config['username'],
                password=self.db_config['password'],
                database=self.db_config['database'],
                charset='utf8mb4',
                autocommit=False
            )
            
            if self.connection.is_connected():
                db_info = self.connection.get_server_info()
                print(f"âœ… Connected to MySQL Server version {db_info}")
                return True
            
        except Error as e:
            print(f"âŒ Error connecting to database: {e}")
            return False

    def load_converted_data(self) -> List[Dict[str, Any]]:
        """åŠ è½½è½¬æ¢åçš„æ•°æ®"""
        json_path = self.output_dir / "game_assets.json"
        
        if not json_path.exists():
            print(f"âŒ Converted data file not found: {json_path}")
            print("Please run 3_convert_format.py first")
            return []
        
        with open(json_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        print(f"ğŸ“¥ Loaded {len(data)} converted assets")
        return data

    def prepare_database(self) -> bool:
        """å‡†å¤‡æ•°æ®åº“è¡¨ç»“æ„"""
        try:
            cursor = self.connection.cursor()
            
            table_name = self.db_config['table']
            
            # æ£€æŸ¥è¡¨æ˜¯å¦å­˜åœ¨
            cursor.execute(f"""
                SELECT COUNT(*) 
                FROM information_schema.tables 
                WHERE table_schema = '{self.db_config['database']}' 
                AND table_name = '{table_name}'
            """)
            
            table_exists = cursor.fetchone()[0] > 0
            
            if table_exists:
                print(f"ğŸ“‹ Table '{table_name}' already exists")
                
                # æ£€æŸ¥ç°æœ‰æ•°æ®
                cursor.execute(f"SELECT COUNT(*) FROM {table_name}")
                existing_count = cursor.fetchone()[0]
                
                if existing_count > 0:
                    print(f"âš ï¸  Table contains {existing_count} existing records")
                    
                    # è¯¢é—®æ˜¯å¦æ¸…ç©ºç°æœ‰æ•°æ®
                    response = input("Do you want to clear existing data? (y/n): ").lower()
                    if response == 'y':
                        print("ğŸ—‘ï¸  Clearing existing data...")
                        cursor.execute(f"DELETE FROM {table_name}")
                        self.connection.commit()
                        print("âœ… Existing data cleared")
                    else:
                        print("ğŸ“ Will append new data to existing records")
            else:
                # åˆ›å»ºè¡¨
                print(f"ğŸ—ï¸  Creating table '{table_name}'...")
                
                create_table_sql = f"""
                CREATE TABLE {table_name} (
                    id BIGINT AUTO_INCREMENT PRIMARY KEY,
                    name VARCHAR(255) NOT NULL,
                    created_at TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP,
                    updated_at TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
                    deleted_at TIMESTAMP NULL,
                    
                    INDEX idx_name (name),
                    INDEX idx_deleted_at (deleted_at)
                ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci
                """
                
                cursor.execute(create_table_sql)
                self.connection.commit()
                print("âœ… Table created successfully")
            
            cursor.close()
            return True
            
        except Error as e:
            print(f"âŒ Error preparing database: {e}")
            return False

    def import_data_batch(self, assets: List[Dict[str, Any]]) -> bool:
        """æ‰¹é‡å¯¼å…¥æ•°æ®"""
        try:
            cursor = self.connection.cursor()
            table_name = self.db_config['table']
            
            print(f"ğŸ“Š Starting batch import of {len(assets)} assets...")
            
            # å‡†å¤‡æ‰¹é‡æ’å…¥SQL
            insert_sql = f"""
                INSERT INTO {table_name} (name, created_at, updated_at) 
                VALUES (%s, %s, %s)
            """
            
            # åˆ†æ‰¹å¤„ç†
            successful_imports = 0
            failed_imports = 0
            
            for i in tqdm(range(0, len(assets), self.batch_size), desc="Importing batches"):
                batch = assets[i:i + self.batch_size]
                
                # å‡†å¤‡æ‰¹é‡æ•°æ®
                batch_data = []
                for asset in batch:
                    batch_data.append((
                        asset['name'],
                        asset['created_at'],
                        asset['updated_at']
                    ))
                
                try:
                    # æ‰§è¡Œæ‰¹é‡æ’å…¥
                    cursor.executemany(insert_sql, batch_data)
                    self.connection.commit()
                    
                    successful_imports += len(batch)
                    
                except Error as e:
                    print(f"âš ï¸  Error in batch {i//self.batch_size + 1}: {e}")
                    failed_imports += len(batch)
                    self.connection.rollback()
                    continue
            
            cursor.close()
            
            print(f"âœ… Import completed:")
            print(f"   ğŸ“ˆ Successful: {successful_imports}")
            print(f"   âŒ Failed: {failed_imports}")
            
            return failed_imports == 0
            
        except Error as e:
            print(f"âŒ Error during import: {e}")
            return False

    def verify_import(self, expected_count: int) -> bool:
        """éªŒè¯å¯¼å…¥ç»“æœ"""
        try:
            cursor = self.connection.cursor()
            table_name = self.db_config['table']
            
            # æ£€æŸ¥æ€»æ•°
            cursor.execute(f"SELECT COUNT(*) FROM {table_name}")
            actual_count = cursor.fetchone()[0]
            
            print(f"ğŸ” Verification results:")
            print(f"   Expected: {expected_count}")
            print(f"   Actual: {actual_count}")
            
            if actual_count >= expected_count:
                print("âœ… Import verification passed")
                
                # æ˜¾ç¤ºæ ·æœ¬æ•°æ®
                cursor.execute(f"SELECT name FROM {table_name} LIMIT 5")
                samples = cursor.fetchall()
                
                print(f"ğŸ“‹ Sample imported data:")
                for i, (name,) in enumerate(samples, 1):
                    print(f"   {i}. {name}")
                
                cursor.close()
                return True
            else:
                print("âŒ Import verification failed")
                cursor.close()
                return False
                
        except Error as e:
            print(f"âŒ Error during verification: {e}")
            return False

    def create_indexes(self) -> bool:
        """åˆ›å»ºé¢å¤–çš„ç´¢å¼•ä»¥ä¼˜åŒ–æŸ¥è¯¢"""
        try:
            cursor = self.connection.cursor()
            table_name = self.db_config['table']
            
            print("ğŸ”§ Creating additional indexes...")
            
            # ä¸ºè‡ªåŠ¨è¡¥å…¨ä¼˜åŒ–çš„å‰ç¼€ç´¢å¼•
            indexes = [
                f"CREATE INDEX idx_{table_name}_name_prefix ON {table_name} (name(10))",
                f"CREATE INDEX idx_{table_name}_created_at ON {table_name} (created_at)",
            ]
            
            for index_sql in indexes:
                try:
                    cursor.execute(index_sql)
                    print(f"   âœ… Created index")
                except Error as e:
                    if "Duplicate key name" in str(e):
                        print(f"   â­ï¸  Index already exists")
                    else:
                        print(f"   âš ï¸  Index creation failed: {e}")
            
            self.connection.commit()
            cursor.close()
            return True
            
        except Error as e:
            print(f"âŒ Error creating indexes: {e}")
            return False

    def generate_import_report(self, assets: List[Dict[str, Any]], success: bool):
        """ç”Ÿæˆå¯¼å…¥æŠ¥å‘Š"""
        report_path = self.output_dir / "import_report.md"
        
        # è·å–æ•°æ®åº“ç»Ÿè®¡
        stats = {}
        if self.connection and self.connection.is_connected():
            try:
                cursor = self.connection.cursor()
                table_name = self.db_config['table']
                
                cursor.execute(f"SELECT COUNT(*) FROM {table_name}")
                stats['total_records'] = cursor.fetchone()[0]
                
                cursor.execute(f"""
                    SELECT COUNT(DISTINCT name) FROM {table_name}
                """)
                stats['unique_names'] = cursor.fetchone()[0]
                
                cursor.execute(f"""
                    SELECT name, COUNT(*) as count 
                    FROM {table_name} 
                    GROUP BY name 
                    HAVING count > 1 
                    LIMIT 10
                """)
                duplicates = cursor.fetchall()
                stats['duplicates'] = duplicates
                
                cursor.close()
                
            except Error as e:
                print(f"âš ï¸  Error collecting stats: {e}")
        
        # ç”ŸæˆæŠ¥å‘Š
        report_content = f"""# æ•°æ®åº“å¯¼å…¥æŠ¥å‘Š

## å¯¼å…¥æ¦‚è§ˆ

- **å¯¼å…¥çŠ¶æ€**: {'âœ… æˆåŠŸ' if success else 'âŒ å¤±è´¥'}
- **å¯¼å…¥æ—¶é—´**: {time.strftime('%Y-%m-%d %H:%M:%S')}
- **æ•°æ®åº“**: {self.db_config['host']}:{self.db_config['port']}/{self.db_config['database']}
- **è¡¨å**: {self.db_config['table']}

## æ•°æ®ç»Ÿè®¡

- **å‡†å¤‡å¯¼å…¥**: {len(assets)} æ¡è®°å½•
- **å®é™…å¯¼å…¥**: {stats.get('total_records', 'N/A')} æ¡è®°å½•
- **å”¯ä¸€åç§°**: {stats.get('unique_names', 'N/A')} ä¸ª

## æ•°æ®è´¨é‡æ£€æŸ¥

"""
        
        if stats.get('duplicates'):
            report_content += "### âš ï¸ å‘ç°é‡å¤æ•°æ®\n\n"
            report_content += "| åç§° | é‡å¤æ¬¡æ•° |\n|------|----------|\n"
            for name, count in stats['duplicates']:
                report_content += f"| {name} | {count} |\n"
        else:
            report_content += "### âœ… æ— é‡å¤æ•°æ®\n"
        
        report_content += f"""
## æ€§èƒ½ä¼˜åŒ–

- å·²åˆ›å»ºåç§°ç´¢å¼•ç”¨äºå¿«é€ŸæŸ¥è¯¢
- å·²åˆ›å»ºå‰ç¼€ç´¢å¼•ç”¨äºè‡ªåŠ¨è¡¥å…¨
- æ‰¹é‡å¤§å°: {self.batch_size}

## æµ‹è¯•æŸ¥è¯¢

å¯ä»¥ä½¿ç”¨ä»¥ä¸‹SQLè¯­å¥æµ‹è¯•è‡ªåŠ¨è¡¥å…¨åŠŸèƒ½:

```sql
-- æµ‹è¯•å‰ç¼€è¡¥å…¨
SELECT name FROM {self.db_config['table']} 
WHERE LOWER(name) LIKE 'åƒç´ %' 
ORDER BY name ASC 
LIMIT 5;

-- æµ‹è¯•æ¨¡ç³Šæœç´¢
SELECT name FROM {self.db_config['table']} 
WHERE LOWER(name) LIKE '%è§’è‰²%' 
ORDER BY name ASC 
LIMIT 10;

-- ç»Ÿè®¡æ•°æ®
SELECT COUNT(*) as total_count FROM {self.db_config['table']};
```

## ä¸‹ä¸€æ­¥

1. é‡å¯SPXåç«¯æœåŠ¡ä»¥åº”ç”¨æ–°æ•°æ®
2. æµ‹è¯•è‡ªåŠ¨è¡¥å…¨APIæ¥å£
3. æ ¹æ®ä½¿ç”¨æƒ…å†µè°ƒæ•´ç´¢å¼•ç­–ç•¥
"""
        
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write(report_content)
        
        print(f"ğŸ“Š Import report saved: {report_path}")

    def close_connection(self):
        """å…³é—­æ•°æ®åº“è¿æ¥"""
        if self.connection and self.connection.is_connected():
            self.connection.close()
            print("ğŸ”Œ Database connection closed")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ“Š Starting database import process...")
    
    importer = DatabaseImporter()
    
    try:
        # æ­¥éª¤1: è¿æ¥æ•°æ®åº“
        if not importer.connect_to_database():
            return
        
        # æ­¥éª¤2: åŠ è½½è½¬æ¢åçš„æ•°æ®
        assets = importer.load_converted_data()
        if not assets:
            return
        
        # æ­¥éª¤3: å‡†å¤‡æ•°æ®åº“
        if not importer.prepare_database():
            return
        
        # æ­¥éª¤4: æ‰¹é‡å¯¼å…¥æ•°æ®
        import_success = importer.import_data_batch(assets)
        
        # æ­¥éª¤5: éªŒè¯å¯¼å…¥ç»“æœ
        verification_success = False
        if import_success:
            verification_success = importer.verify_import(len(assets))
        
        # æ­¥éª¤6: åˆ›å»ºä¼˜åŒ–ç´¢å¼•
        if verification_success:
            importer.create_indexes()
        
        # æ­¥éª¤7: ç”ŸæˆæŠ¥å‘Š
        final_success = import_success and verification_success
        importer.generate_import_report(assets, final_success)
        
        if final_success:
            print("âœ… Database import completed successfully!")
            print("ğŸ‰ You can now test the auto-completion API!")
        else:
            print("âŒ Database import failed. Please check the errors above.")
            
    except KeyboardInterrupt:
        print("\nâ¹ï¸  Import process interrupted by user")
    except Exception as e:
        print(f"âŒ Unexpected error: {e}")
    finally:
        importer.close_connection()

if __name__ == "__main__":
    main()
